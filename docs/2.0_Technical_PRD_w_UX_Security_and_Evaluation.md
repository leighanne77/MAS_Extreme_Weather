This is in .gitignore

# Tool PRD - LLM-Powered Natural Capital Risk Assessment

**Date Created**: June 20, 2025
**Date Last Updated**: June 29, 2025

## Table of Contents

1. [Core Problem](#1-core-problem) âœ… **Defined**
2. [Solution Overview](#2-solution-overview) âœ… **Implemented**
3. [What Tool Does Not Do](#3-what-tool-does-not-do) âœ… **Defined** - See [Do_not_do.md](Do_not_do.md) for comprehensive restrictions
4. [Key Requirements](#4-key-requirements) âœ… **Implemented**
5. [Development Priorities](#5-development-priorities) ðŸ”„ **In Progress**
6. [Confidential Compute Data Sharing](#6-confidential-compute-data-sharing) âœ… **Implemented**
7. [Technical Stack](#7-technical-stack) âœ… **Implemented**
8. [Implementation Status](#8-implementation-status) ðŸ”„ **In Progress** - See [ADK_A2A_Usage_Table.md](ADK_A2A_Usage_Table.md) for detailed status
9. [Requirements for Agent Architecture](#9-requirements-for-agent-architecture) âœ… **Implemented** - See [A2A_ADK_Rationale.md](A2A_ADK_Rationale.md) for technical rationale
10. [A2A Protocol Implementation](#10-a2a-protocol-implementation) âœ… **Complete** - See [A2A_reference.md](A2A_reference.md) and [a2a_integration.md](a2a_integration.md)
11. [Agent Design Principles](#11-agent-design-principles) âœ… **Implemented** - See [agentcard.md](agentcard.md) for design guidelines
12. [Agent Behavior Guidelines](#12-agent-behavior-guidelines) âœ… **Implemented** - See [agent_guidelines.md](agent_guidelines.md) for comprehensive guidelines
13. [Data Sources](#13-data-sources) âœ… **Implemented** - See [First_Data_Sources.md](First_Data_Sources.md) for comprehensive data source documentation
14. [Quality Assurance Framework](#14-quality-assurance-framework) âœ… **Implemented**
15. [Comprehensive Data Integration](#15-comprehensive-data-integration) âœ… **Implemented**
16. [Delivery Model](#16-delivery-model) ðŸ“‹ **Planned**
17. [Output Formats & Customization](#17-output-formats--customization) âœ… **Implemented**
18. [Query Interface Design](#18-query-interface-design) âœ… **Implemented**
19. [Web Dashboard Interface](#19-web-dashboard-interface) âœ… **Complete** - See [Pythia_UX.md](Pythia_UX.md) for UX requirements
20. [Agent Observability](#20-agent-observability) âœ… **Implemented**
21. [Multi-Agent Security Framework](#21-multi-agent-security-framework) ðŸ”„ **In Progress** - See [Security_Additions.md](Security_Additions.md) for security challenges
22. [Geographic Prototypes](#22-geographic-prototypes) âœ… **Implemented** - See [DRAFT_prototypes_user_journeys.md](DRAFT_prototypes_user_journeys.md) for detailed user journeys
23. [Risk Assessment Framework](#23-risk-assessment-framework) âœ… **Implemented**

## Related Documentation
- [terms_used.md](terms_used.md) - Comprehensive list of all agents, components, and terminology used in the system
- [project_structure.md](project_structure.md) - Complete project structure and file organization documentation
- [user_personas.md](user_personas.md) - Detailed user persona definitions and requirements
- [user_story.md](user_story.md) - Complete user story documentation and requirements
- [1.1_System_and_architecture_overview.md](1.1_System_and_architecture_overview.md) - System architecture overview and technical specifications

## 1. Core Problem
Capital market actors lack tools to quantify financial risks from environmental degradation and extreme weather, and lack actionable nature-first resilience solutions when assessing an investable asset, a current investments, a loans, etc. 

## 2. Solution Overview
Multi-agent LLM system that:
- Quantifies extreme weather, heat and related environmental risks for investment portfolios
- Provides nature-first resilience recommendations 
- Focuses on 5-7 year investment horizons
- Delivers bioregional decision support
- For investors, managers, owners, bankers, and other capital market actors

## 3. What Tool Does Not Do 
- Calculates IRR: Tool does not access any of the proprietary data of our capital market users but augments their work
- Automates Risk Decisions: Tool provides decision support, and does not wade into regulated industry decision automations
- Portfolio-level (investments or loans) risk analysis: Tool only works on one action on one asset or loan or other financial action at a time
- Insurance options: Tool does not do any insurance-related advising

**For comprehensive restrictions and guidelines, see [Do_not_do.md](Do_not_do.md)**

## 4. Key Requirements
1. Transform complex data on extreme weather and risks into actionable business insights
2. Support capital allocation decisions
3. Provide bioregional resilience recommendations
4. Serve non-expert users with natural language interfaces
5. Deliver outputs suitable for IRR calculations and existing financial models
6. Ensure secure multi-agent communications and data protection
7. Implement comprehensive threat detection and monitoring

## 5. Development Priorities
1. âœ… Agent system architecture with observability
2. âœ… Natural language query processing
3. âœ… Data pipeline integration
4. âœ… Risk assessment algorithms
5. âœ… Customizable output generation
6. ðŸ”„ Production deployment and scaling
7. ðŸ”„ Advanced machine learning integration
8. ðŸ“‹ Multi-agent security framework implementation
9. ðŸ“‹ A2A protocol security hardening
10. ðŸ“‹ Threat detection and monitoring systems

## 6. Confidential Compute Data Sharing

### **Overview**
Tool will leverage Google Cloud's Confidential Compute capabilities to enable secure data sharing with scientists, researchers, and other data providers while maintaining strict data privacy and sovereignty.

### **Advanced: Architecture Approach**
- **Confidential Space**: Utilize Google Cloud's Confidential Space for secure data processing
- **Data Isolation**: Keep raw data encrypted and isolated from Tool's analysis engine
- **Zero-Knowledge Processing**: Tool can analyze data without ever seeing the raw values
- **Secure Enclaves**: Process data in hardware-protected enclaves with verified execution

### **Data Sharing Workflows**
1. **Data Provider Upload**: Scientists and researchers upload encrypted data to Confidential Space
2. **Secure Processing**: Tool runs analysis on encrypted data within secure enclaves
3. **Result Extraction**: Only aggregated risk metrics and insights are extracted
4. **Data Retention**: Raw data remains encrypted and inaccessible to Tool

### **Security Benefits**
- **Auditability**: All data access is logged and verifiable
- **Regulatory Compliance**: Meets requirements for data privacy and protection
- **Trust Building**: Enables collaboration with sensitive datasets
- **Data Sovereignty**: Data owners maintain full control over their data


### **Implementation Considerations**
- **Performance**: Confidential Compute adds latency but enables access to new data sources
- **Cost Management**: Additional compute costs for secure processing
- **Integration**: Seamless integration with existing Tool workflows
- **Scalability**: Can handle multiple data sources simultaneously

### **Technical Integration**
- **API Endpoints**: Secure APIs for data providers to upload encrypted data
- **Processing Pipeline**: Automated analysis within Confidential Space
- **Result Delivery**: Secure delivery of insights to Tool users
- **Monitoring**: Real-time monitoring of data processing and access

### **Community Knowledge Integration**
- **Citizen Science Platforms**: Integration with iNaturalist, eBird, and other citizen science platforms
- **Local Expert Verification**: Verification systems for local knowledge holders and practitioners
- **Indigenous Knowledge Protocols**: Respectful protocols for traditional ecological knowledge
- **Nonprofit Verification**: Integration with Charity Navigator and other verification systems
- **Community Data Standards**: Standardized formats for community-contributed data
- **Knowledge Attribution**: Proper attribution and recognition for community contributors

### **Usage-Based Payment System**
- **Google Payments Integration**: Secure payment processing for data contributors
- **Opt-in Compensation**: Data providers can choose to receive payment for their contributions
- **Usage-Based Pricing**: Payment based on data quality, volume, and usage frequency
- **Transparent Pricing**: Clear pricing structure and payment schedules
- **Automatic Payments**: Automated payment processing and distribution
- **Payment Verification**: Secure verification of data contributions and payments

### **Security Threat Modeling**
- **MAESTRO Framework Integration**: AI-specific threat modeling for multi-agent systems
- **Zero-Trust Architecture**: Never trust, always verify agent interactions
- **Defense in Depth**: Multiple security layers at network, application, and agent levels
- **Comprehensive Logging**: Detailed audit trails for all agent interactions


**All Users, Value Propositions are found in [Draft_value_propositions.md](Draft_value_propositions.md)**

**Detailed User Journeys and Economic Problems are Found in [DRAFT_prototypes_user_journeys.md](DRAFT_prototypes_user_journeys.md)**

**UX Requirements and Technical Integration Details are Found in [Pythia_UX.md](Pythia_UX.md)**

## 7. Technical Stack

| Component | Technology | Purpose | Status |
|-----------|------------|---------|---------|
| Agent Framework | Google ADK | Multi-agent orchestration | âœ… Complete |
| Agent Protocol | Google A2A | Secure agent communication | âœ… Complete |
| ML Operations | Titan/Vertex AI | Production deployment | ðŸ”„ In Progress |
| LLM | Gemini 2.5 | Advanced reasoning | âœ… Complete |
| Cloud | GCP + Confidential Space | Secure data sharing | âœ… Complete |
| Payments | Google Pay APIs | Expert attribution | ðŸ”„ In Progress |
| Frontend | Vanilla JavaScript + FastAPI | Web interface | âœ… Complete |
| Data Visualization | Chart.js | Interactive charts | âœ… Complete |
| Database | SQLite + PostgreSQL | Data storage | âœ… Complete |

## 8. Implementation Status
- [ADK_A2A_Usage_Table.md](ADK_A2A_Usage_Table.md) - Comprehensive ADK and A2A implementation status and compliance details
- [A2A_Reference.md](A2A_Reference.md) - A2A protocol reference and implementation details
- [a2a_integration.md](a2a_integration.md) - Complete A2A protocol implementation documentation

## 9. Requirements for Agent Architecture
Multi-agent system with specialized agents for:
- Task decomposition and orchestration
- Data analysis and synthesis including from local knowledge holders using Google Confidential Compute to share safely with the users 
- Risk assessment across different natural capital types
- Financial impact modeling
- Nature-first solution recommendations

**Technical Rationale**: See [A2A_ADK_Rationale.md](A2A_ADK_Rationale.md) for detailed technical decisions and integration rationale

## 10. A2A Protocol Implementation âœ…
The system now includes a **complete A2A (Agent-to-Agent) protocol implementation** with:

### 10.1 **A2A Core Components**
1. **Message Structure** (`src/multi_agent_system/a2a/message.py`) âœ…
   - Complete A2A message envelope implementation
   - Message headers with correlation IDs and expiration
   - Message validation and serialization
   - Support for all A2A message types

2. **Message Parts** (`src/multi_agent_system/a2a/parts.py`) âœ…
   - Text, data, file, and binary part types
   - Part validation and serialization
   - Content type handling

3. **Message Router** (`src/multi_agent_system/a2a/router.py`) âœ…
   - Agent registration and discovery
   - Message routing and delivery
   - Broadcast message support
   - Heartbeat monitoring

4. **Task Management** (`src/multi_agent_system/a2a/task_manager.py`) âœ…
   - Complete task lifecycle management
   - Task state tracking (created, running, completed, failed, cancelled, timeout)
   - Task execution with timeout handling
   - Task cleanup and statistics

5. **Artifact Management** (`src/multi_agent_system/a2a/artifact_manager.py`) âœ…
   - Full artifact lifecycle management
   - Artifact storage and retrieval
   - Permission checking and access control
   - Artifact versioning and metadata

6. **Content Handlers** (`src/multi_agent_system/a2a/content_handlers.py`) âœ…
   - Text, data, file, image, audio, and video handlers
   - Content serialization and deserialization
   - Content validation and type checking
   - Handler registry for extensibility

## 11. Agent Design Principles
- [agentcard.md](agentcard.md) - Agent card documentation and design guidelines

### 11.1 **Implementation Guidelines:**
- Required fields: name, description, URL, version, capabilities, input/output modes, skills
- Security: Always use HTTPS, implement bearer token authentication, define access controls
- Capabilities: Enable streaming, push notifications, state transition history as needed
- Skills: Keep skills focused, document dependencies, specify error conditions
- Media Types: Support JSON for structured data, plain text for natural language, domain-specific formats

## 12. Agent Behavior Guidelines
- [agent_guidelines.md](agent_guidelines.md) - Comprehensive agent behavior and tool usage guidelines

**Core Behavior Principles:**
### 12.1 **Tool Usage Standards**: Always check tool return status, handle errors appropriately, verify confidence scores
### 12.2 **Error Recovery**: Implement retry with exponential backoff for transient errors, fallback to alternative tools for permanent errors
### 12.3 **Data Quality**: Validate location data, use multiple data sources, include confidence levels, document data lineage
### 12.4 **Nature-First Approach**: Prioritize nature-based solutions over structural solutions, consider local ecosystem compatibility
### 12.5 **Financial Transparency**: Provide clear cost estimates with ranges, include ROI calculations, account for maintenance costs
### 12.6 **Communication Standards**: Use clear structured messages, include necessary context, handle communication errors gracefully
### 12.7 **Security Practices**: Validate all inputs, implement proper authentication, handle sensitive data appropriately
### 12.8 **Performance Optimization**: Implement caching strategies, use parallel processing, monitor resource usage
### 12.9 **Quality Assurance**: Follow PEP 8 guidelines, implement comprehensive testing, use type hints throughout
### 12.10 **Workflow Consistency**: Follow standardized phases for data collection, risk assessment, solution generation, and recommendation delivery

### 12.11 **Climate Risk Analysis Specific Guidelines:**
- Always validate location data before risk analysis
- Use multiple data sources for cross-validation
- Include confidence levels in all assessments
- Prioritize nature-based solutions over structural solutions
- Provide clear cost estimates with ROI calculations
- Document methodology and data sources
- Implement graceful degradation for service failures

## 13. Data Sources
- Geospatial and climate data
- Agricultural and financial market data
- Expert knowledge from specialists
- Nature-first mitigation datasets
- **Enhanced International Data Sources** (see [First_Data_Sources.md](First_Data_Sources.md))

## Data Standardization
- Transparent methodology documentation for due diligence
- Version control for data sources and model updates

## 14. Quality Assurance Framework
- Data lineage and source attribution
- Model validation against historical events
- Peer review processes for nature-first recommendations
- Clear disclaimers and limitations


## 15. Comprehensive Data Integration
The system now includes extensive data source integration across all prototypes:

### 15.1 **West Kansas Prototype**
- **Core Water Management**: OpenET API, USGS Water Data, USDA Agricultural Data
- **Biodiversity**: USDA NRCS, USFWS, Pollinator Data, Soil Health Data
- **Advanced Climate**: NOAA Weather APIs, Climate Prediction Center, Local Weather Networks

### 15.2 **Caribbean Islands + South Florida Prototype**
- **Hurricane Data**: NOAA National Hurricane Center, USGS Storm Surge, FEMA Flood Maps
- **Tourism Impact**: Tourism Industry Data, Property Value Data, Insurance Industry Data
- **Local Environmental**: Florida DEP, Fish and Wildlife, Local Economic Indicators

### 15.3 **North Carolina (Inland) Prototype**
- **Energy Infrastructure**: Energy Information Administration, Department of Transportation
- **Technology Performance**: Industry databases, Academic research data
- **Climate Data**: National Weather Service, Water Availability, Energy Grid Reliability

### 15.4 **Mobile Bay, Alabama Prototype**
- **Opportunity Zone Data**: Census tract designations, Novogradac QOF tracking, Investment trends
- **Climate Risks**: NOAA Hurricane Center, USGS projections, FEMA assessments
- **Local Development**: Alabama state agencies, University research, Extension data

### 15.5 **Deccan Plateau, India Prototype**
- **Climate Data**: IPCC projections, NASA satellite data, Academic research
- **Government Data**: Indian Meteorological Department, Central Water Commission, Ministry data
- **Rural Development**: NABARD, ICAR, Local environmental agencies

## 16. Delivery Model
- Open core (free community version)
- Commercial enterprise versions
- Freemium model with SLAs

## 17. Output Formats & Customization
- Structured data exports (JSON, CSV, API endpoints)
- Configurable risk metrics and time horizons
- Custom report templates and data views
- Integration hooks for existing financial modeling tools

## 18. Query Interface Design
- Natural language input (no SQL required): "What are water risks for cattle operations in western Kansas over the next 7 years?"
- Simple parameter specification (location, asset type, time horizon, risk categories)
- Batch processing capabilities for multiple assets/locations
- API-first approach for programmatic access
- Minimal UI focused on configuration and data export

## 19. Web Dashboard Interface âœ…
The system now includes a complete web dashboard interface with:

### 19.1 **Technology Stack**
- **Frontend**: Vanilla JavaScript, Chart.js, CSS Grid/Flexbox
- **Backend**: FastAPI, Google ADK, A2A Protocol
- **Data Sources**: NOAA SWDI, Nature-Based Solutions Database, Enhanced Data Sources
- **Visualization**: Chart.js with dynamic chart selection
- **Mobile**: Responsive design for all devices
- **API**: RESTful endpoints with JSON responses

### 19.2 **Key Features**
- **User Type Selection**: 8 specialized user types with tailored features
- **Location Input**: Text entry or interactive map selection
- **Natural Language Queries**: AI-powered query processing
- **Advanced Filtering**: Multiple filter categories for precise results
- **Dynamic Visualizations**: Various chart types with real-time updates
- **Export Options**: Multiple format downloads (JSON, PDF, Excel, Presentation)

**For detailed UX requirements and specifications, see [Pythia_UX.md](Pythia_UX.md)**

## 20. Agent Observability
- Real-time monitoring of agent performance and decision-making
- Audit trails for all agent interactions and data retrievals
- Performance metrics and error tracking across the multi-agent system
- Debugging capabilities for complex agent workflows

## 21. Multi-Agent Security Framework

### 21.1 **A2A Protocol Security**
- **Agent Identity Verification**: Cryptographic controls for agent authentication
- **AgentCard Validation**: Secure AgentCard creation and validation
- **Message Schema Security**: Robust A2A message validation
- **Task Authorization**: Granular permission control for agent tasks

### 21.2 **Threat Detection and Prevention**
- **Agent Card Spoofing Prevention**: Cryptographic verification of AgentCards
- **Task Replay Protection**: Nonce-based task validation
- **Server Impersonation Detection**: Certificate-based server verification
- **Cross-Agent Escalation Prevention**: Capability-based access control

### 21.3 **Monitoring and Auditing**
- **A2A Communication Monitoring**: Real-time monitoring of agent communications
- **Artifact Integrity Verification**: Checksums and digital signatures for artifacts
- **Insider Threat Detection**: Behavioral analysis of agent actions
- **Supply Chain Security**: Dependency scanning and verification

### 21.4 **Security Threat Modeling**
- **MAESTRO Framework Integration**: AI-specific threat modeling for multi-agent systems
- **Zero-Trust Architecture**: Never trust, always verify agent interactions
- **Defense in Depth**: Multiple security layers at network, application, and agent levels
- **Comprehensive Logging**: Detailed audit trails for all agent interactions

**For comprehensive security challenges and solutions, see [Security_Additions.md](Security_Additions.md)**

## 22. Implementation Status

### 22.1 **Completed Components âœ…**
1. **Complete A2A Protocol Implementation**
   - Message structure, routing, task management, artifact management
   - All A2A protocol components fully implemented and tested
   - Agent-to-agent communication with full protocol compliance

2. **Multi-Agent System Architecture**
   - Base agent class with A2A support
   - Specialized agents for risk analysis, historical data, recommendations
   - Agent team coordination and session management

3. **Web Dashboard Interface**
   - Complete frontend with Vanilla JavaScript and FastAPI backend
   - Natural language query processing
   - Interactive data visualization with Chart.js
   - Responsive design for all devices

4. **Enhanced Data Sources**
   - Comprehensive data integration across all prototypes
   - International data sources for global coverage
   - Specialized data for each user type and region

5. **Agentic Data Management**
   - Complete data management system with specialized agents
   - Data quality, security, and governance frameworks
   - Integration with Google Cloud services

### 22.2 **In Progress ðŸ”„**
1. **Production Deployment**
   - GCP deployment configuration
   - Performance optimization and load testing
   - Security hardening and compliance
   - A2A protocol security implementation
   - Multi-agent threat detection systems

2. **Advanced Features**
   - Machine learning integration for predictive analytics
   - Real-time data processing capabilities
   - Advanced visualization and reporting

3. **Payment System Integration**
   - Google Pay APIs integration
   - Usage-based payment processing
   - Data contributor compensation system

### 22.3 **Planned ðŸ“‹**
1. **Enterprise Features**
   - Advanced security and compliance features
   - Multi-agent security framework
   - A2A-specific threat modeling
   - Custom integrations and APIs
   - White-label solutions

2. **Global Expansion**
   - Additional regional data sources
   - Multi-language support
   - International regulatory compliance

3. **Advanced Analytics**
   - Machine learning risk models
   - Predictive analytics and trend analysis
   - Advanced scenario modeling

## 23. Geographic Prototypes - Pythia UX Requirement
- **West Kansas Prototype**: Water Management, Biodiversity, Advanced Climate
- **Caribbean Islands + South Florida Prototype**: Hurricane Data, Tourism Impact, Local Environmental
- **North Carolina (Inland) Prototype**: Energy Infrastructure, Technology Performance, Climate Data
- **Mobile Bay, Alabama Prototype**: Opportunity Zone Data, Climate Risks, Local Development
- **Deccan Plateau, India Prototype**: Climate Data, Government Data, Rural Development

**For detailed user journeys and economic problems, see [DRAFT_prototypes_user_journeys.md](DRAFT_prototypes_user_journeys.md)**

## 24. Risk Assessment Framework - Pythia UX Requirement
- **Risk Analysis**: Comprehensive risk analysis across different natural capital types
- **Scenario Modeling**: Advanced scenario modeling for future climate scenarios
- **Decision Support**: Bioregional decision support for capital allocation

## Change Log

### **June 29, 2025**
- **Document Enhancement**: Added date headers and change log
- **Technical Updates**: Updated implementation status and technical specifications
- **Security Integration**: Enhanced confidential compute and security documentation
- **Document Reorganization**: Restructured with numbered sections, implementation status, and comprehensive documentation links

### **June 20, 2025**
- **Initial Creation**: Established comprehensive technical PRD

---

**Last Updated**: January 2025
**Version**: 2.0
**Status**: Complete A2A Implementation, Web Dashboard, Enhanced Data Sources
